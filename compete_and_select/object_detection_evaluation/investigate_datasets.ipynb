{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5391fec-390a-4a3d-8530-1cd21611a4a3",
   "metadata": {},
   "source": [
    "# Investigating OCIDRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf347d23-7eb7-4845-8d7e-99b13a40def0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "OCID_ref_root = '/scratch/gsk6me/WORLDMODELS/OCID-Ref'\n",
    "\n",
    "with open(os.path.join(OCID_ref_root, \"train_expressions.json\")) as f:\n",
    "    train_expressions = json.load(f)\n",
    "\n",
    "with open(os.path.join(OCID_ref_root, \"val_expressions.json\")) as f:\n",
    "    val_expressions = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde3c633-0872-4aa8-b614-9f2e756a5bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = sorted(train_expressions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a4bd66-389e-408e-a889-e03489fe7f93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Key: 83152\n",
      "{'seq_id': 83, 'scene_id': 898, 'take_id': 18, 'scene_path': 'ARID20/floor/top/seq06/rgb/result_2018-08-20-11-37-31.png', 'sequence_path': 'ARID20/floor/top/seq06', 'sub_dataset': 'ARID20', 'instance_id': 5527, 'scene_instance_id': 18, 'class': 'food_box', 'class_instance': 'food_box_2', 'new_class': 'box', 'sentence': 'The food_box behind and on the bottom-left of the sponge.', 'tokens': ['The', 'food_box', 'behind', 'and', 'on', 'the', 'bottom-left', 'of', 'the', 'sponge'], 'bbox': '[172, 182, 259, 323]', 'sentence_id': '83152'}\n",
      "---\n",
      "Key: 10545\n",
      "{'seq_id': 12, 'scene_id': 129, 'take_id': 9, 'scene_path': 'ARID10/floor/top/mixed/seq02/rgb/result_2018-08-24-17-08-45.png', 'sequence_path': 'ARID10/floor/top/mixed/seq02', 'sub_dataset': 'ARID10', 'instance_id': 705, 'scene_instance_id': 2, 'class': 'kleenex', 'class_instance': 'kleenex_3', 'new_class': 'box', 'sentence': 'The kleenex in front and on the bottom-right of the ball.', 'tokens': ['The', 'kleenex', 'in', 'front', 'and', 'on', 'the', 'bottom-right', 'of', 'the', 'ball'], 'bbox': '[361, 212, 491, 285]', 'sentence_id': '10545'}\n",
      "---\n",
      "Key: 234408\n",
      "{'seq_id': 125, 'scene_id': 1739, 'take_id': 19, 'scene_path': 'ARID20/table/bottom/seq09/rgb/result_2018-08-21-15-58-00.png', 'sequence_path': 'ARID20/table/bottom/seq09', 'sub_dataset': 'ARID20', 'instance_id': 14353, 'scene_instance_id': 9, 'class': 'potato', 'class_instance': 'potato_1', 'new_class': 'vegetable', 'sentence': 'The potato on the front left.', 'tokens': ['The', 'potato', 'on', 'the', 'front', 'left'], 'bbox': '[35, 293, 100, 336]', 'sentence_id': '234408'}\n",
      "---\n",
      "Key: 35687\n",
      "{'seq_id': 45, 'scene_id': 455, 'take_id': 5, 'scene_path': 'ARID10/table/top/curved/seq18/rgb/result_2018-08-23-13-33-14.png', 'sequence_path': 'ARID10/table/top/curved/seq18', 'sub_dataset': 'ARID10', 'instance_id': 2491, 'scene_instance_id': 4, 'class': 'apple', 'class_instance': 'apple_1', 'new_class': 'fruit', 'sentence': 'The red yellow object.', 'tokens': ['The', 'red', 'yellow', 'object'], 'bbox': '[254, 218, 295, 256]', 'sentence_id': '35687'}\n",
      "---\n",
      "Key: 261958\n",
      "{'seq_id': 139, 'scene_id': 1916, 'take_id': 6, 'scene_path': 'YCB10/floor/top/mixed/seq02/rgb/result_2018-08-24-10-19-41.png', 'sequence_path': 'YCB10/floor/top/mixed/seq02', 'sub_dataset': 'YCB10', 'instance_id': 15727, 'scene_instance_id': 6, 'class': 'bleach_cleanser', 'class_instance': 'bleach_cleanser_1', 'new_class': 'bottle', 'sentence': 'The bleach_cleanser on the rear left.', 'tokens': ['The', 'bleach_cleanser', 'on', 'the', 'rear', 'left'], 'bbox': '[338, 121, 402, 213]', 'sentence_id': '261958'}\n",
      "---\n",
      "Key: 13383\n",
      "{'seq_id': 15, 'scene_id': 158, 'take_id': 8, 'scene_path': 'ARID10/floor/top/non-fruits/seq09/rgb/result_2018-08-27-16-13-28.png', 'sequence_path': 'ARID10/floor/top/non-fruits/seq09', 'sub_dataset': 'ARID10', 'instance_id': 867, 'scene_instance_id': 8, 'class': 'shampoo', 'class_instance': 'shampoo_3', 'new_class': 'bottle', 'sentence': 'The red plastic shampoo on the rear right of the blue food_box.', 'tokens': ['The', 'red', 'plastic', 'shampoo', 'on', 'the', 'rear', 'right', 'of', 'the', 'blue', 'food_box'], 'bbox': '[311, 256, 350, 307]', 'sentence_id': '13383'}\n",
      "---\n",
      "Key: 58881\n",
      "{'seq_id': 72, 'scene_id': 728, 'take_id': 8, 'scene_path': 'ARID10/table/bottom/mixed/seq13/rgb/result_2018-08-23-12-04-09.png', 'sequence_path': 'ARID10/table/bottom/mixed/seq13', 'sub_dataset': 'ARID10', 'instance_id': 3997, 'scene_instance_id': 4, 'class': 'cereal_box', 'class_instance': 'cereal_box_1', 'new_class': 'box', 'sentence': 'The box on the rear right.', 'tokens': ['The', 'box', 'on', 'the', 'rear', 'right'], 'bbox': '[331, 112, 478, 216]', 'sentence_id': '58881'}\n",
      "---\n",
      "Key: 297089\n",
      "{'seq_id': 171, 'scene_id': 2235, 'take_id': 5, 'scene_path': 'YCB10/table/bottom/curved/seq26/rgb/result_2018-08-24-14-11-31.png', 'sequence_path': 'YCB10/table/bottom/curved/seq26', 'sub_dataset': 'YCB10', 'instance_id': 17477, 'scene_instance_id': 3, 'class': 'pitcher_base', 'class_instance': 'pitcher_base_1', 'new_class': 'cup', 'sentence': 'The cup on the rear right of the ball.', 'tokens': ['The', 'cup', 'on', 'the', 'rear', 'right', 'of', 'the', 'ball'], 'bbox': '[328, 14, 407, 146]', 'sentence_id': '297089'}\n",
      "---\n",
      "Key: 285379\n",
      "{'seq_id': 160, 'scene_id': 2128, 'take_id': 8, 'scene_path': 'YCB10/table/top/curved/seq35/rgb/result_2018-08-24-15-06-19.png', 'sequence_path': 'YCB10/table/top/curved/seq35', 'sub_dataset': 'YCB10', 'instance_id': 16896, 'scene_instance_id': 6, 'class': 'mini_soccer_ball', 'class_instance': 'mini_soccer_ball_1', 'new_class': 'ball', 'sentence': 'The brown mini_soccer_ball on the front right.', 'tokens': ['The', 'brown', 'mini_soccer_ball', 'on', 'the', 'front', 'right'], 'bbox': '[315, 280, 389, 361]', 'sentence_id': '285379'}\n",
      "---\n",
      "Key: 170855\n",
      "{'seq_id': 109, 'scene_id': 1416, 'take_id': 16, 'scene_path': 'ARID20/table/top/seq06/rgb/result_2018-08-21-13-57-28.png', 'sequence_path': 'ARID20/table/top/seq06', 'sub_dataset': 'ARID20', 'instance_id': 10939, 'scene_instance_id': 9, 'class': 'stapler', 'class_instance': 'stapler_2', 'new_class': 'stapler', 'sentence': 'The brown smooth stapler.', 'tokens': ['The', 'brown', 'smooth', 'stapler'], 'bbox': '[332, 246, 350, 315]', 'sentence_id': '170855'}\n"
     ]
    }
   ],
   "source": [
    "# Print a sample\n",
    "i = 0\n",
    "for key, expression in train_expressions.items():\n",
    "    print(\"---\")\n",
    "    print(\"Key:\", key)\n",
    "    print(expression)\n",
    "    i += 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a65bb-ae0a-4011-9763-1d2413ce8e79",
   "metadata": {},
   "source": [
    "### Thoughts\n",
    "\n",
    "We need to replace underscores with spaces.\n",
    "\n",
    "Almost every example is of the format (potentially descriptive object designation) \\[(preposition) (other object)\\]\n",
    "\n",
    "Will there be enough data here, though?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814fc5c6-a5d5-4b6f-a1d6-0056b402442e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259839"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_expressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a402f17b-a51b-4e89-a59e-48fe1159411f",
   "metadata": {},
   "source": [
    "It's possible there is enough data, but I am unsure whether the model will be able to suss out the minor details like colors and such."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408528af-16fb-43d8-b528-b53029f1b437",
   "metadata": {},
   "source": [
    "# Investigating RefCOCOg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc9032ed-6411-4c3c-a7f4-273d18cd8acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import refer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4d85e3-55d2-49ad-90c3-2c7cb6121d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset refcocog into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=7.55s)\n"
     ]
    }
   ],
   "source": [
    "ds = refer.REFER(\n",
    "    data_root='/scratch/gsk6me/WORLDMODELS/refcoco',\n",
    "    image_root='/scratch/gsk6me/WORLDMODELS',\n",
    "    dataset='refcocog',\n",
    "    splitBy='umd'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "378f4518-4e2f-4844-99f1-b8d9c3d2204b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_ids = ds.getRefIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "336016a1-4a92-4e40-bfe0-82109052e6af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[380440]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.getImgIds(ref_ids[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "758262c7-6fde-4974-a320-2577a6607062",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image_id': 380440,\n",
       "  'split': 'test',\n",
       "  'sentences': [{'tokens': ['the', 'man', 'in', 'yellow', 'coat'],\n",
       "    'raw': 'the man in yellow coat',\n",
       "    'sent_id': 8,\n",
       "    'sent': 'the man in yellow coat'},\n",
       "   {'tokens': ['skiier', 'in', 'red', 'pants'],\n",
       "    'raw': 'Skiier in red pants.',\n",
       "    'sent_id': 9,\n",
       "    'sent': 'skiier in red pants'}],\n",
       "  'file_name': 'COCO_train2014_000000380440_491042.jpg',\n",
       "  'category_id': 1,\n",
       "  'ann_id': 491042,\n",
       "  'sent_ids': [8, 9],\n",
       "  'ref_id': 0}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.loadRefs(ref_ids[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2b661d5-a580-4ed6-bb08-ad0577e04c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating rows: 100%|██████████| 49822/49822 [01:13<00:00, 673.65it/s] \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "# let's make a dataset.\n",
    "rows_per_split = {'train': [], 'val': [], 'test': []}\n",
    "\n",
    "image_sizes = {}\n",
    "\n",
    "coco_split = 'train'\n",
    "\n",
    "\n",
    "for ref_id, ref in tqdm.tqdm(ds.Refs.items(), desc='Generating rows', total=len(ds.Refs)):\n",
    "    # Multiple refs can refer to the same object (which is an annotation)\n",
    "    annot = ds.Anns[ref['ann_id']]\n",
    "    \n",
    "    coco_dir = f'/scratch/gsk6me/WORLDMODELS/{coco_split}2014'\n",
    "    image_url = f\"{coco_dir}/COCO_{coco_split}2014_{ref['image_id']:012d}.jpg\"\n",
    "    if image_url in image_sizes:\n",
    "        width, height = image_sizes[image_url]\n",
    "    else:\n",
    "        image = PIL.Image.open(image_url).convert(\"RGB\")\n",
    "        width = image.width\n",
    "        height = image.height\n",
    "        image_sizes[image_url] = (width, height)\n",
    "\n",
    "    # Get relative bounding box\n",
    "    x1, y1, x2, y2 = annot['bbox']\n",
    "    bbox_relative = np.array([x1 / width, y1 / height, x2 / width, y2 / height])\n",
    "    bbox_relative *= 1024\n",
    "    bbox_relative = bbox_relative.astype(int)\n",
    "    x1, y1, x2, y2 = bbox_relative\n",
    "\n",
    "    # Construct a prompt.\n",
    "    prefix = f\"Describe <loc{x1:04d}><loc{y1:04d}><loc{x2:04d}><loc{y2:04d}>\"\n",
    "\n",
    "    for sentence in ref['sentences']:\n",
    "        suffix = \"Answer: \" + sentence['sent']\n",
    "\n",
    "        rows_per_split[ref['split']].append({\n",
    "            \"image\": image_url,\n",
    "            \"prefix\": prefix,\n",
    "            \"suffix\": suffix,\n",
    "        })\n",
    "\n",
    "# generate jsonl\n",
    "for split in rows_per_split:\n",
    "    with open(f\"refcocog_{split}.jsonl\", \"w\") as f:\n",
    "        for row in rows_per_split[split]:\n",
    "            json.dump(row, f)\n",
    "            f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf2e48c2-1bb4-4bc5-a0d6-4ebe6edc0107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO_val2014_000000000042.jpg\n",
      "COCO_val2014_000000000073.jpg\n",
      "COCO_val2014_000000000074.jpg\n",
      "COCO_val2014_000000000133.jpg\n",
      "COCO_val2014_000000000136.jpg\n",
      "ls: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!ls /scratch/gsk6me/WORLDMODELS/val2014 | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b690df37-9786-4014-bbe1-57c5184272e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000380440.jpg\", \"prefix\": \"Describe <loc0598><loc0177><loc0217><loc0549>\", \"suffix\": \"Answer: the man in yellow coat\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000380440.jpg\", \"prefix\": \"Describe <loc0598><loc0177><loc0217><loc0549>\", \"suffix\": \"Answer: skiier in red pants\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000419645.jpg\", \"prefix\": \"Describe <loc0150><loc0197><loc0807><loc0690>\", \"suffix\": \"Answer: there is red colored truck in between the other trucks\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000419645.jpg\", \"prefix\": \"Describe <loc0150><loc0197><loc0807><loc0690>\", \"suffix\": \"Answer: a shiny red vintage pickup truck\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000478885.jpg\", \"prefix\": \"Describe <loc0542><loc0197><loc0235><loc0378>\", \"suffix\": \"Answer: a apple desktop computer\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000478885.jpg\", \"prefix\": \"Describe <loc0542><loc0197><loc0235><loc0378>\", \"suffix\": \"Answer: the white imac computer that is also turned on\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000323240.jpg\", \"prefix\": \"Describe <loc0072><loc0355><loc0235><loc0383>\", \"suffix\": \"Answer: a girl wearing glasses and a pink shirt\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000323240.jpg\", \"prefix\": \"Describe <loc0072><loc0355><loc0235><loc0383>\", \"suffix\": \"Answer: an asian girl with a pink shirt eating at the table\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000041700.jpg\", \"prefix\": \"Describe <loc0793><loc0308><loc0132><loc0628>\", \"suffix\": \"Answer: woman in coveralls\"}\n",
      "{\"image\": \"/scratch/gsk6me/WORLDMODELS/train2014/COCO_train2014_000000041700.jpg\", \"prefix\": \"Describe <loc0793><loc0308><loc0132><loc0628>\", \"suffix\": \"Answer: a person wearing overalls\"}\n"
     ]
    }
   ],
   "source": [
    "!head refcocog_train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d942e64-d40b-4ef9-a6b0-c9376d28210a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cas_env",
   "language": "python",
   "name": "cas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
